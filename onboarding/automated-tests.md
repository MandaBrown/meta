## Automated Tests
TTM makes heavy use of automation in quality assurance. This helps us ensure that new code or changes do not cause regression issues in the platform, and it also allows us to baseline changes to understand what technical and performance impact changes will have. Developers are expected to include automated tests with their code. Most tests set up one or more randomized data structures and then test whether typical use of the code will produce an expected output, given random input. We use the following types of tests:
* **Fast Tests**: Fast tests are meant to cover individual functionality or libraries without database interaction. Some times that's because the tested code doesn't need a database, and sometimes we will stub out the data layer because it's not critical to the test.
* **Unit Tests**: Unit tests cover specific functionality or libraries, and may need to create data structures in order to assess the test.
* **Integration Tests**: Integration tests are meant to cover interactions between modules in the TTM application. These are run through a headless web browser  that is invoked specifically for the test. Integration tests 'drive' the application similar to how an actual user would interact with the site, so they can be useful for ensuring that common workflows still operate correctly after refactoring.
* **UI Tests**: These tests cover page rendering in all supported environments.  It will render pages and compare them to a stored control image.
* **Post-Deploy Tests**: These tests cover core application workflows. They are automatically triggered after every deployment to the RC and production farms. Post-deploy tests serve as a final check to make sure that we haven't impacted any of the core site functions in production, since sometimes a change can be fine in a local and QA environment but interact badly with the production infrastructure.
* **Performance Tests**: Performance tests are implemented in JMeter. They are run nightly on the RC farm, and they test the student and teacher core experience using a fixed quantity of teachers and students. Results from the test are recorded through New Relic, and are compared to previous runs to determine whether we have improved throughput and response time, or made it worse.
* **Security Tests**: the Jenkins CI server will run the Brakeman security scanner against all candidate branches. Errors found will be reported as issues on the pull request.
